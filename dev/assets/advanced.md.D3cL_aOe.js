import{_ as s,c as i,o as a,a7 as e}from"./chunks/framework.BMhi3Yu-.js";const u=JSON.parse('{"title":"Advanced","description":"","frontmatter":{},"headers":[],"relativePath":"advanced.md","filePath":"advanced.md","lastUpdated":null}'),n={name:"advanced.md"},t=e(`<h1 id="Advanced" tabindex="-1">Advanced <a class="header-anchor" href="#Advanced" aria-label="Permalink to &quot;Advanced {#Advanced}&quot;">​</a></h1><h2 id="Using-Ollama-Models" tabindex="-1">Using Ollama Models <a class="header-anchor" href="#Using-Ollama-Models" aria-label="Permalink to &quot;Using Ollama Models {#Using-Ollama-Models}&quot;">​</a></h2><p>AIHelpMe can use Ollama models (locally-hosted models), but the knowledge packs are available for only one embedding model: &quot;nomic-embed-text&quot;!</p><p>You must set <code>model_embedding=&quot;nomic-embed-text&quot;</code> and <code>truncate_dimension=0</code> (maximum dimension available) for everything to work correctly!</p><p>Example:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> PromptingTools</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> register_model!, OllamaSchema</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> AIHelpMe</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> update_pipeline!, load_index!</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># register model names with the Ollama schema</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">register_model!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(; name</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;mistral:7b-instruct-v0.2-q4_K_M&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,schema</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">OllamaSchema</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">())</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">register_model!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(; name</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;nomic-embed-text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,schema</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">OllamaSchema</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">())</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># you can use whichever chat model you like!</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">update_pipeline!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:bronze</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; model_chat </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;mistral:7b-instruct-v0.2-q4_K_M&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,model_embedding</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;nomic-embed-text&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, truncate_dimension</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># You must download the corresponding knowledge packs via \`load_index!\` (because you changed the embedding model)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">load_index!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">:julia</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># or whichever other packs you want!</span></span></code></pre></div><p>Let&#39;s ask a question:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">aihelp</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;How to create a named tuple?&quot;</span></span></code></pre></div><div class="language-plaintext vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">plaintext</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span>[ Info: Done with RAG. Total cost: \\$0.0</span></span>
<span class="line"><span>PromptingTools.AIMessage(&quot;In Julia, you can create a named tuple by enclosing key-value pairs in parentheses with the keys as symbols preceded by a colon, separated by commas. For example:</span></span>
<span class="line"><span>...continues</span></span></code></pre></div><h2 id="Extending-the-Knowledge-Base" tabindex="-1">Extending the Knowledge Base <a class="header-anchor" href="#Extending-the-Knowledge-Base" aria-label="Permalink to &quot;Extending the Knowledge Base {#Extending-the-Knowledge-Base}&quot;">​</a></h2><p>The package by default ships with pre-processed embeddings for all Julia standard libraries, DataFrames and PromptingTools. Thanks to the amazing Julia Artifacts system, these embeddings are downloaded/cached/loaded every time the package starts.</p><p>Note: The below functions are not yet exported. Prefix them with <code>AIHelpMe.</code> to use them.</p><h3 id="Building-and-Updating-Indexes" tabindex="-1">Building and Updating Indexes <a class="header-anchor" href="#Building-and-Updating-Indexes" aria-label="Permalink to &quot;Building and Updating Indexes {#Building-and-Updating-Indexes}&quot;">​</a></h3><p>AIHelpMe allows users to enhance its capabilities by embedding documentation from any loaded Julia module. Utilize <code>new_index = build_index(module)</code> to create an index for a specific module (or a vector of modules).</p><p>To update an existing index, including newly imported packages, use <code>new index = update_index(module)</code> or simply <code>update_index()</code> to include all unrecognized modules. We will add and embed only the new documentation to avoid unnecessary duplication and cost.</p><h3 id="Managing-Indexes" tabindex="-1">Managing Indexes <a class="header-anchor" href="#Managing-Indexes" aria-label="Permalink to &quot;Managing Indexes {#Managing-Indexes}&quot;">​</a></h3><p>Once an index is built or updated, you can choose to serialize it for later use or set it as the primary index.</p><p>To use your newly created index as the main source for queries, execute <code>load_index!(new_index)</code>. Alternatively, load a pre-existing index from a file using <code>load_index!(file_path)</code>.</p><p>The main index for queries is held in the global variable <code>AIHelpMe.MAIN_INDEX[]</code>.</p><h2 id="Help-Us-Improve-and-Debug" tabindex="-1">Help Us Improve and Debug <a class="header-anchor" href="#Help-Us-Improve-and-Debug" aria-label="Permalink to &quot;Help Us Improve and Debug {#Help-Us-Improve-and-Debug}&quot;">​</a></h2><p>It would be incredibly helpful if you could share examples when the pipeline fails. We&#39;re particularly interested in cases where the answer you get is wrong because of the &quot;bad&quot; context provided.</p><p>Let&#39;s say you ran a question and got a wrong answer (or some other aspect is worth reporting).</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">aihelp</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;how to create tuples in julia?&quot;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Bad answer somehow...</span></span></code></pre></div><p>You can access the underlying pipeline internals (what context was used etc.)</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># last result (debugging object RAGResult)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">result</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">AIHelpMe</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">last_result</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># If you want to see the actual context snippets, use \`add_context=true\`</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">AIHelpMe</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">pprint</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(result)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Or access the fields in RAGResult directly, eg,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">result</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">context</span></span></code></pre></div><p>Let&#39;s save this result for debugging later into JSON.</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> AIHelpMe</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PromptingTools</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> JSON3</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">config_key </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> AIHelpMe</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">get_config_key</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">() </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># &quot;nomicembedtext-0-Bool&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">JSON3</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">write</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;rag-makie-xyzyzyz-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">$(config_key)</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">-20240419.json&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, result)</span></span></code></pre></div><p>Now, you want to let us know. Please share the above JSON with a few notes of what you expected/what is wrong via a Github Issue or on Slack (<code>#generative-ai</code> channel)!</p>`,28),l=[t];function p(h,d,o,k,r,c){return a(),i("div",null,l)}const E=s(n,[["render",p]]);export{u as __pageData,E as default};
