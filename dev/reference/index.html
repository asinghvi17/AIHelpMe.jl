<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reference · AIHelpMe.jl</title><meta name="title" content="Reference · AIHelpMe.jl"/><meta property="og:title" content="Reference · AIHelpMe.jl"/><meta property="twitter:title" content="Reference · AIHelpMe.jl"/><meta name="description" content="Documentation for AIHelpMe.jl."/><meta property="og:description" content="Documentation for AIHelpMe.jl."/><meta property="twitter:description" content="Documentation for AIHelpMe.jl."/><meta property="og:url" content="https://svilupp.github.io/PromptingTools.jl/reference/"/><meta property="twitter:url" content="https://svilupp.github.io/PromptingTools.jl/reference/"/><link rel="canonical" href="https://svilupp.github.io/PromptingTools.jl/reference/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">AIHelpMe.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../faq/">F.A.Q</a></li><li class="is-active"><a class="tocitem" href>Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Reference</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/svilupp/AIHelpMe.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/svilupp/AIHelpMe.jl/blob/main/docs/src/reference.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h1><ul><li><a href="#AIHelpMe.aihelp-Tuple{PromptingTools.Experimental.RAGTools.AbstractChunkIndex, AbstractString}"><code>AIHelpMe.aihelp</code></a></li><li><a href="#AIHelpMe.docdata_to_source-Tuple{AbstractDict}"><code>AIHelpMe.docdata_to_source</code></a></li><li><a href="#AIHelpMe.docextract"><code>AIHelpMe.docextract</code></a></li><li><a href="#AIHelpMe.docextract"><code>AIHelpMe.docextract</code></a></li><li><a href="#AIHelpMe.docextract-Tuple{Module}"><code>AIHelpMe.docextract</code></a></li><li><a href="#AIHelpMe.docextract"><code>AIHelpMe.docextract</code></a></li><li><a href="#AIHelpMe.find_new_chunks-Tuple{AbstractVector{&lt;:AbstractString}, AbstractVector{&lt;:AbstractString}}"><code>AIHelpMe.find_new_chunks</code></a></li><li><a href="#AIHelpMe.last_context-Tuple{}"><code>AIHelpMe.last_context</code></a></li><li><a href="#AIHelpMe.load_index!"><code>AIHelpMe.load_index!</code></a></li><li><a href="#AIHelpMe.load_index!-Tuple{PromptingTools.Experimental.RAGTools.AbstractChunkIndex}"><code>AIHelpMe.load_index!</code></a></li><li><a href="#AIHelpMe.preview_context"><code>AIHelpMe.preview_context</code></a></li><li><a href="#AIHelpMe.update_index"><code>AIHelpMe.update_index</code></a></li><li><a href="#PromptingTools.Experimental.RAGTools.build_index"><code>PromptingTools.Experimental.RAGTools.build_index</code></a></li><li><a href="#PromptingTools.Experimental.RAGTools.build_index-Tuple{Module}"><code>PromptingTools.Experimental.RAGTools.build_index</code></a></li><li><a href="#AIHelpMe.@aihelp!_str-Tuple{Any, Vararg{Any}}"><code>AIHelpMe.@aihelp!_str</code></a></li><li><a href="#AIHelpMe.@aihelp_str-Tuple{Any, Vararg{Any}}"><code>AIHelpMe.@aihelp_str</code></a></li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.aihelp-Tuple{PromptingTools.Experimental.RAGTools.AbstractChunkIndex, AbstractString}" href="#AIHelpMe.aihelp-Tuple{PromptingTools.Experimental.RAGTools.AbstractChunkIndex, AbstractString}"><code>AIHelpMe.aihelp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">aihelp([index::RAG.AbstractChunkIndex,]
    question::AbstractString;
    rag_template::Symbol = :RAGAnswerFromContext,
    top_k::Int = 100, top_n::Int = 5,
    minimum_similarity::AbstractFloat = -1.0,
    maximum_cross_similarity::AbstractFloat = 1.0,
    rerank_strategy::RAG.RerankingStrategy = (!isempty(PT.COHERE_API_KEY) ?
                                              RAG.CohereRerank() : RAG.Passthrough()),
    annotate_sources::Bool = true,
    model_embedding::String = PT.MODEL_EMBEDDING, model_chat::String = PT.MODEL_CHAT,
    chunks_window_margin::Tuple{Int, Int} = (1, 1),
    return_context::Bool = false, verbose::Integer = 1,
    rerank_kwargs::NamedTuple = NamedTuple(),
    api_kwargs::NamedTuple = NamedTuple(),
    kwargs...)</code></pre><p>Generates a response for a given question using a Retrieval-Augmented Generation (RAG) approach over Julia documentation. </p><p><strong>Arguments</strong></p><ul><li><code>index::AbstractChunkIndex</code>: The chunk index (contains chunked and embedded documentation).</li><li><code>question::AbstractString</code>: The question to be answered.</li><li><code>rag_template::Symbol</code>: Template for the RAG model, defaults to <code>:RAGAnswerFromContext</code>.</li><li><code>top_k::Int</code>: Number of top candidates to retrieve based on embedding similarity.</li><li><code>top_n::Int</code>: Number of candidates to return after reranking. This is how many will be sent to the LLM model.</li><li><code>minimum_similarity::AbstractFloat</code>: Minimum similarity threshold (between -1 and 1) for filtering chunks based on embedding similarity. Defaults to -1.0.</li><li><code>maximum_cross_similarity::AbstractFloat</code>: Maximum cross-similarity threshold to avoid sending duplicate documents. NOT IMPLEMENTED YET</li><li><code>rerank_strategy::RerankingStrategy</code>: Strategy for reranking the retrieved chunks. Defaults to <code>Passthrough()</code> or <code>CohereRerank</code> depending on whether <code>COHERE_API_KEY</code> is set.</li><li><code>model_embedding::String</code>: Model used for embedding the question, default is <code>PT.MODEL_EMBEDDING</code>.</li><li><code>model_chat::String</code>: Model used for generating the final response, default is <code>PT.MODEL_CHAT</code>.</li><li><code>chunks_window_margin::Tuple{Int,Int}</code>: The window size around each chunk to consider for context building. See <code>?build_context</code> for more information.</li><li><code>return_context::Bool</code>: If <code>true</code>, returns the context used for RAG along with the response.</li><li><code>return_all::Bool</code>: If <code>true</code>, returns all messages in the conversation (helpful to continue conversation later).</li><li><code>verbose::Bool</code>: If <code>true</code>, enables verbose logging.</li><li><code>rerank_kwargs</code>: Reranking parameters that will be forwarded to the reranking strategy</li><li><code>api_kwargs</code>: API parameters that will be forwarded to the API calls</li></ul><p><strong>Returns</strong></p><ul><li>If <code>return_context</code> is <code>false</code>, returns the generated message (<code>msg</code>).</li><li>If <code>return_context</code> is <code>true</code>, returns a tuple of the generated message (<code>msg</code>) and the RAG context (<code>rag_context</code>).</li></ul><p><strong>Notes</strong></p><ul><li>The function first finds the closest chunks of documentation to the question (via <code>embeddings</code>).</li><li>It reranks the candidates and builds a &quot;context&quot; for the RAG model (ie, information to be provided to the LLM model together with the user question).</li><li>The <code>chunks_window_margin</code> allows including surrounding chunks for richer context, considering they are from the same source.</li><li>The function currently supports only single <code>ChunkIndex</code>. </li><li>Function always saves the last context in global <code>LAST_CONTEXT</code> for inspection of sources/context regardless of <code>return_context</code> value.</li></ul><p><strong>Examples</strong></p><p>Using <code>aihelp</code> to get a response for a question:</p><pre><code class="language-julia hljs">index = build_index(...)  # create an index that contains Makie.jl documentation
question = &quot;How to make a barplot in Makie.jl?&quot;
msg = aihelp(index, question)

# or simply
msg = aihelp(index; question)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/generation.jl#L1-L61">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.docdata_to_source-Tuple{AbstractDict}" href="#AIHelpMe.docdata_to_source-Tuple{AbstractDict}"><code>AIHelpMe.docdata_to_source</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">docdata_to_source(data::AbstractDict)</code></pre><p>Creates a source path from a given DocStr record</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/preparation.jl#L1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.docextract" href="#AIHelpMe.docextract"><code>AIHelpMe.docextract</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">docextract(d::DocStr, sep::AbstractString = &quot;</code></pre><p>&quot;)</p><p>Extracts the documentation from a DocStr record. Separates the individual docs within <code>DocStr</code> with <code>sep</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/preparation.jl#L14-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.docextract" href="#AIHelpMe.docextract"><code>AIHelpMe.docextract</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">docextract(d::MultiDoc, sep::AbstractString = &quot;</code></pre><p>&quot;)</p><p>Extracts the documentation from a MultiDoc record (separates the individual docs within <code>DocStr</code> with <code>sep</code>)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/preparation.jl#L35-L41">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.docextract" href="#AIHelpMe.docextract"><code>AIHelpMe.docextract</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">docextract(modules::Vector{Module} = Base.Docs.modules)</code></pre><p>Extracts the documentation from a vector of <code>modules</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/preparation.jl#L71-L75">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.docextract-Tuple{Module}" href="#AIHelpMe.docextract-Tuple{Module}"><code>AIHelpMe.docextract</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">docextract(mod::Module)</code></pre><p>Extracts the documentation from a given (loaded) module.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/preparation.jl#L50-L54">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.find_new_chunks-Tuple{AbstractVector{&lt;:AbstractString}, AbstractVector{&lt;:AbstractString}}" href="#AIHelpMe.find_new_chunks-Tuple{AbstractVector{&lt;:AbstractString}, AbstractVector{&lt;:AbstractString}}"><code>AIHelpMe.find_new_chunks</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">find_new_chunks(old_chunks::AbstractVector{&lt;:AbstractString},
    new_chunks::AbstractVector{&lt;:AbstractString})</code></pre><p>Identifies the new chunks in <code>new_chunks</code> that are not present in <code>old_chunks</code>.</p><p>Returns a mask of chunks that are new (not present in <code>old_chunks</code>).</p><p>Uses SHA256 hashes to dedupe the strings quickly and effectively.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/utils.jl#L3-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.last_context-Tuple{}" href="#AIHelpMe.last_context-Tuple{}"><code>AIHelpMe.last_context</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">last_context()</code></pre><p>Returns the RAGContext from the last <code>aihelp</code> call.  It can be useful to see the sources/references used by the AI model to generate the response.</p><p>If you&#39;re using <code>aihelp()</code> make sure to set <code>return_context = true</code> to return the context.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/utils.jl#L41-L48">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.load_index!" href="#AIHelpMe.load_index!"><code>AIHelpMe.load_index!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">load_index!(file_path::Union{Nothing, AbstractString} = nothing;
    verbose::Bool = true, kwargs...)</code></pre><p>Loads the serialized index in <code>file_path</code> into the global variable <code>MAIN_INDEX</code>. If not provided, it will download the latest index from the AIHelpMe.jl repository (more cost-efficient).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/utils.jl#L118-L124">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.load_index!-Tuple{PromptingTools.Experimental.RAGTools.AbstractChunkIndex}" href="#AIHelpMe.load_index!-Tuple{PromptingTools.Experimental.RAGTools.AbstractChunkIndex}"><code>AIHelpMe.load_index!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">load_index!(index::RAG.AbstractChunkIndex;
    verbose::Bool = 1, kwargs...)</code></pre><p>Loads the provided <code>index</code> into the global variable <code>MAIN_INDEX</code>.</p><p>If you don&#39;t have an <code>index</code> yet, use <code>build_index</code> to build one from your currently loaded packages (see <code>?build_index</code>)</p><p><strong>Example</strong></p><pre><code class="language-julia hljs"># build an index from some modules, keep empty to embed all loaded modules (eg, `build_index()`) 
index = AIH.build_index([DataFramesMeta, DataFrames, CSV])
AIH.load_index!(index)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/utils.jl#L96-L110">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.preview_context" href="#AIHelpMe.preview_context"><code>AIHelpMe.preview_context</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">preview_context(context = last_context())</code></pre><p>Preview the context of the last <code>aihelp</code> call. It will pretty-print the question, context and answer in the REPL.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/utils.jl#L57-L62">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.update_index" href="#AIHelpMe.update_index"><code>AIHelpMe.update_index</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">update_index(index::RAG.AbstractChunkIndex = MAIN_INDEX,
    modules::Vector{Module} = Base.Docs.modules;
    verbose::Integer = 1,
    separators = [&quot;\n\n&quot;, &quot;. &quot;, &quot;\n&quot;], max_length::Int = 256,
    model::AbstractString = PT.MODEL_EMBEDDING,
    kwargs...)
    modules::Vector{Module} = Base.Docs.modules;
    verbose::Bool = true, kwargs...)</code></pre><p>Updates the provided <code>index</code> with the documentation of the provided <code>modules</code>.</p><p>Deduplicates against the <code>index.sources</code> and embeds only the new document chunks (as measured by a hash).</p><p>Returns the updated <code>index</code> (new instance).</p><p><strong>Example</strong></p><p>If you loaded some new packages and want to add them to your MAIN_INDEX (or any <code>index</code> you use), run:</p><pre><code class="language-julia hljs"># To update the MAIN_INDEX
AHM.update_index() |&gt; AHM.load_index!

# To update an explicit index
index = AHM.update_index(index)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/utils.jl#L144-L169">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.Experimental.RAGTools.build_index" href="#PromptingTools.Experimental.RAGTools.build_index"><code>PromptingTools.Experimental.RAGTools.build_index</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">RAG.build_index(modules::Vector{Module} = Base.Docs.modules; verbose::Int = 1,
    separators = [&quot;</code></pre><p>&quot;, &quot;. &quot;, &quot; &quot;], max_length::Int = 256,         kwargs...)</p><p>Build index from the documentation of the currently loaded modules. If <code>modules</code> is empty, it will use all currently loaded modules.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/preparation.jl#L99-L109">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.Experimental.RAGTools.build_index-Tuple{Module}" href="#PromptingTools.Experimental.RAGTools.build_index-Tuple{Module}"><code>PromptingTools.Experimental.RAGTools.build_index</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">RAG.build_index(mod::Module; verbose::Int = 1, kwargs...)</code></pre><p>Build <code>index</code> from the documentation of a given module <code>mod</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/preparation.jl#L86-L90">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.@aihelp!_str-Tuple{Any, Vararg{Any}}" href="#AIHelpMe.@aihelp!_str-Tuple{Any, Vararg{Any}}"><code>AIHelpMe.@aihelp!_str</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">aihelp!&quot;user_question&quot;[model_alias] -&gt; AIMessage</code></pre><p>The <code>aihelp!&quot;&quot;</code> string macro is used to continue a previous conversation with the AI model. </p><p>It appends the new user prompt to the last conversation in the tracked history (in <code>AIHelpMe.CONV_HISTORY</code>) and generates a response based on the entire conversation context. If you want to see the previous conversation, you can access it via <code>AIHelpMe.CONV_HISTORY</code>, which keeps at most last <code>PromptingTools.MAX_HISTORY_LENGTH</code> conversations.</p><p>It does NOT provide new context from the documentation. To do that, start a new conversation with <code>aihelp&quot;&lt;question&gt;&quot;</code>.</p><p><strong>Arguments</strong></p><ul><li><code>user_question</code> (String): The follow up question to be added to the existing conversation.</li><li><code>model_alias</code> (optional, any): Specify the model alias of the AI model to be used (see <code>PT.MODEL_ALIASES</code>). If not provided, the default model is used.</li></ul><p><strong>Returns</strong></p><p><code>AIMessage</code> corresponding to the new user prompt, considering the entire conversation history.</p><p><strong>Example</strong></p><p>To continue a conversation:</p><pre><code class="language-julia hljs"># start conversation as normal
aihelp&quot;How to create a dictionary?&quot; 

# ... wait for reply and then react to it:

# continue the conversation (notice that you can change the model, eg, to more powerful one for better answer)
aihelp!&quot;Can you create it from named tuple?&quot;gpt4t
# AIMessage(&quot;Yes, you can create a dictionary from a named tuple ...&quot;)</code></pre><p><strong>Usage Notes</strong></p><ul><li>This macro should be used when you want to maintain the context of an ongoing conversation (ie, the last <code>ai&quot;&quot;</code> message).</li><li>It automatically accesses and updates the global conversation history.</li><li>If no conversation history is found, it raises an assertion error, suggesting to initiate a new conversation using <code>ai&quot;&quot;</code> instead.</li></ul><p><strong>Important</strong></p><p>Ensure that the conversation history is not too long to maintain relevancy and coherence in the AI&#39;s responses. The history length is managed by <code>MAX_HISTORY_LENGTH</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/macros.jl#L48-L85">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.@aihelp_str-Tuple{Any, Vararg{Any}}" href="#AIHelpMe.@aihelp_str-Tuple{Any, Vararg{Any}}"><code>AIHelpMe.@aihelp_str</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">aihelp&quot;user_question&quot;[model_alias] -&gt; AIMessage</code></pre><p>The <code>aihelp&quot;&quot;</code> string macro generates an AI response to a given user question by using <code>aihelp</code> under the hood. It will automatically try to provide the most relevant bits of the documentation (from the index) to the LLM to answer the question.</p><p>See also <code>aihelp!&quot;&quot;</code> if you want to reply to the provided message / continue the conversation.</p><p><strong>Arguments</strong></p><ul><li><code>user_question</code> (String): The question to be answered by the AI model.</li><li><code>model_alias</code> (optional, any): Provide model alias of the AI model (see <code>MODEL_ALIASES</code>).</li></ul><p><strong>Returns</strong></p><p><code>AIMessage</code> corresponding to the input prompt.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">result = aihelp&quot;Hello, how are you?&quot;
# AIMessage(&quot;Hello! I&#39;m an AI assistant, so I don&#39;t have feelings, but I&#39;m here to help you. How can I assist you today?&quot;)</code></pre><p>If you want to interpolate some variables or additional context, simply use string interpolation:</p><pre><code class="language-julia hljs">a=1
result = aihelp&quot;What is `$a+$a`?&quot;
# AIMessage(&quot;The sum of `1+1` is `2`.&quot;)</code></pre><p>If you want to use a different model, eg, GPT-4, you can provide its alias as a flag:</p><pre><code class="language-julia hljs">result = aihelp&quot;What is `1.23 * 100 + 1`?&quot;gpt4t
# AIMessage(&quot;The answer is 124.&quot;)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/265d262e3fff4049b135929534fa73bdda22f6eb/src/macros.jl#L1-L34">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../faq/">« F.A.Q</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Tuesday 23 January 2024 08:34">Tuesday 23 January 2024</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
