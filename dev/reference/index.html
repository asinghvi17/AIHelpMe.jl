<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Reference · AIHelpMe.jl</title><meta name="title" content="Reference · AIHelpMe.jl"/><meta property="og:title" content="Reference · AIHelpMe.jl"/><meta property="twitter:title" content="Reference · AIHelpMe.jl"/><meta name="description" content="Documentation for AIHelpMe.jl."/><meta property="og:description" content="Documentation for AIHelpMe.jl."/><meta property="twitter:description" content="Documentation for AIHelpMe.jl."/><meta property="og:url" content="https://svilupp.github.io/PromptingTools.jl/reference/"/><meta property="twitter:url" content="https://svilupp.github.io/PromptingTools.jl/reference/"/><link rel="canonical" href="https://svilupp.github.io/PromptingTools.jl/reference/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">AIHelpMe.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../faq/">F.A.Q</a></li><li class="is-active"><a class="tocitem" href>Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Reference</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/svilupp/AIHelpMe.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/svilupp/AIHelpMe.jl/blob/main/docs/src/reference.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h1><ul><li><a href="#AIHelpMe.ALLOWED_PACKS"><code>AIHelpMe.ALLOWED_PACKS</code></a></li><li><a href="#AIHelpMe.RAG_CONFIGURATIONS"><code>AIHelpMe.RAG_CONFIGURATIONS</code></a></li><li><a href="#AIHelpMe.aihelp-Tuple{PromptingTools.Experimental.RAGTools.AbstractRAGConfig, PromptingTools.Experimental.RAGTools.AbstractChunkIndex, AbstractString}"><code>AIHelpMe.aihelp</code></a></li><li><a href="#AIHelpMe.docdata_to_source-Tuple{AbstractDict}"><code>AIHelpMe.docdata_to_source</code></a></li><li><a href="#AIHelpMe.docextract"><code>AIHelpMe.docextract</code></a></li><li><a href="#AIHelpMe.docextract-Tuple{Module}"><code>AIHelpMe.docextract</code></a></li><li><a href="#AIHelpMe.docextract"><code>AIHelpMe.docextract</code></a></li><li><a href="#AIHelpMe.docextract"><code>AIHelpMe.docextract</code></a></li><li><a href="#AIHelpMe.find_new_chunks-Tuple{AbstractVector{&lt;:AbstractString}, AbstractVector{&lt;:AbstractString}}"><code>AIHelpMe.find_new_chunks</code></a></li><li><a href="#AIHelpMe.get_config_key-Tuple{PromptingTools.Experimental.RAGTools.AbstractRAGConfig, NamedTuple}"><code>AIHelpMe.get_config_key</code></a></li><li><a href="#AIHelpMe.last_result-Tuple{}"><code>AIHelpMe.last_result</code></a></li><li><a href="#AIHelpMe.load_index!-Tuple{Vector{Symbol}}"><code>AIHelpMe.load_index!</code></a></li><li><a href="#AIHelpMe.load_index!-Tuple{AbstractString}"><code>AIHelpMe.load_index!</code></a></li><li><a href="#AIHelpMe.load_index!-Tuple{PromptingTools.Experimental.RAGTools.AbstractChunkIndex}"><code>AIHelpMe.load_index!</code></a></li><li><a href="#AIHelpMe.load_index_hdf5-Tuple{AbstractString}"><code>AIHelpMe.load_index_hdf5</code></a></li><li><a href="#AIHelpMe.update_index"><code>AIHelpMe.update_index</code></a></li><li><a href="#AIHelpMe.update_pipeline!"><code>AIHelpMe.update_pipeline!</code></a></li><li><a href="#PromptingTools.Experimental.RAGTools.build_index-Tuple{Module}"><code>PromptingTools.Experimental.RAGTools.build_index</code></a></li><li><a href="#PromptingTools.Experimental.RAGTools.build_index"><code>PromptingTools.Experimental.RAGTools.build_index</code></a></li><li><a href="#AIHelpMe.@aihelp!_str-Tuple{Any, Vararg{Any}}"><code>AIHelpMe.@aihelp!_str</code></a></li><li><a href="#AIHelpMe.@aihelp_str-Tuple{Any, Vararg{Any}}"><code>AIHelpMe.@aihelp_str</code></a></li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.ALLOWED_PACKS" href="#AIHelpMe.ALLOWED_PACKS"><code>AIHelpMe.ALLOWED_PACKS</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia hljs">ALLOWED PACKS</code></pre><p>Currently available packs are:</p><ul><li><code>:julia</code> - Julia documentation, standard library docstrings and a few extras (for Julia v1.10)</li><li><code>:tidier</code> - Tidier.jl organization documentation (as of 7th April 2024)</li><li><code>:makie</code> - Makie.jl organization documentation and a few extras (as of 30th March 2024)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/pipeline_defaults.jl#L7-L14">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.RAG_CONFIGURATIONS" href="#AIHelpMe.RAG_CONFIGURATIONS"><code>AIHelpMe.RAG_CONFIGURATIONS</code></a> — <span class="docstring-category">Constant</span></header><section><div><pre><code class="language-julia hljs">RAG_CONFIGURATIONS</code></pre><p>A dictionary of RAG configurations, keyed by a unique symbol (eg, <code>bronze</code>). Each entry contains a dictionary with keys <code>:config</code> and <code>:kwargs</code>, where <code>:config</code> is the RAG configuration object (<code>AbstractRAGConfig</code>) and <code>:kwargs</code> the NamedTuple of corresponding kwargs.</p><p>Available Options:</p><ul><li><code>:bronze</code>: A simple configuration for a bronze pipeline, using truncated binary embeddings (dimensionality: 1024) and no re-ranking or refinement.</li><li><code>:silver</code>: A simple configuration for a bronze pipeline, using truncated binary embeddings (dimensionality: 1024) but also enables re-ranking and refinement with a web-search.</li><li><code>:gold</code>: A more complex configuration, similar to <code>:simpler</code>, but using a standard embeddings (dimensionality: 3072, type: Float32). It also leverages re-ranking and refinement with a web-search.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/pipeline_defaults.jl#L28-L39">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.aihelp-Tuple{PromptingTools.Experimental.RAGTools.AbstractRAGConfig, PromptingTools.Experimental.RAGTools.AbstractChunkIndex, AbstractString}" href="#AIHelpMe.aihelp-Tuple{PromptingTools.Experimental.RAGTools.AbstractRAGConfig, PromptingTools.Experimental.RAGTools.AbstractChunkIndex, AbstractString}"><code>AIHelpMe.aihelp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">aihelp([cfg::RT.AbstractRAGConfig, index::RT.AbstractChunkIndex,]
    question::AbstractString;
    verbose::Integer = 1,
    model = MODEL_CHAT,
    return_all::Bool = false)</code></pre><p>Generates a response for a given question using a Retrieval-Augmented Generation (RAG) approach over Julia documentation (or any other knowledge pack). </p><p>If you return RAGResult (<code>return_all=true</code>), you can use <code>AIHelpMe.pprint</code> to pretty-print the result and see the sources/&quot;support&quot; scores for each chunk of the answer.</p><p>The answer will depend on the knowledge packs loaded, see <code>?load_index!</code>.</p><p>You can also use add docstrings from any package you have loaded (or all of them), see <code>?update_index</code> and make sure to provide your new updated index explicitly!</p><p><strong>Arguments</strong></p><ul><li><code>cfg::AbstractRAGConfig</code>: The RAG configuration.</li><li><code>index::AbstractChunkIndex</code>: The chunk index (contains chunked and embedded documentation).</li><li><code>question::AbstractString</code>: The question to be answered.</li><li><code>model::String</code>: A chat/generation model used for generating the final response, default is <code>MODEL_CHAT</code>.</li><li><code>return_all::Bool</code>: If <code>true</code>, returns a <code>RAGResult</code> (provides details of the pipeline + allows pretty-printing with <code>pprint(result)</code>).</li><li><code>search::Union{Nothing, Bool}</code>: If <code>true</code>, uses TavilySearchRefiner to add web search results to the context. See <code>?PromptingTools.Experimental.RAGTools.TavilySearchRefiner</code> for details.</li><li><code>rerank::Union{Nothing, Bool}</code>: If <code>true</code>, uses CohereReranker to rerank the chunks. See <code>?PromptingTools.Experimental.RAGTools.CohereReranker</code> for details.</li></ul><p><strong>Returns</strong></p><ul><li>If <code>return_all</code> is <code>false</code>, returns the generated message (<code>msg</code>).</li><li>If <code>return_all</code> is <code>true</code>, returns a <code>RAGResult</code> (provides details of the pipeline + allows pretty-printing with <code>pprint(result)</code>)</li></ul><p><strong>Notes</strong></p><ul><li>Function always saves the last context in global <code>LAST_RESULT</code> for inspection of sources/context regardless of <code>return_all</code> value.</li></ul><p><strong>Examples</strong></p><p>Using <code>aihelp</code> to get a response for a question:</p><pre><code class="language-julia hljs">using AIHelpMe: build_index

index = build_index(...)  # create an index that contains Makie.jl documentation (or any loaded package that you have)

question = &quot;How to make a barplot in Makie.jl?&quot;
msg = aihelp(index, question)</code></pre><p>If you want a pretty-printed answer with highlighted sources, you can use the <code>return_all</code> argument and <code>pprint</code> utility:</p><pre><code class="language-julia hljs">using AIHelpMe: pprint

result = aihelp(index, question; return_all = true)
pprint(result)</code></pre><p>If you loaded a knowledge pack, you do not have to provide the index.</p><pre><code class="language-julia hljs"># Load Makie knowledge pack
AIHelpMe.load_index!(:makie)

question = &quot;How to make a barplot in Makie.jl?&quot;
msg = aihelp(question)</code></pre><p>If you know it&#39;s a hard question, you can use the <code>search</code> and <code>rerank</code> arguments to add web search results to the context and rerank the chunks.</p><pre><code class="language-julia hljs">using AIHelpMe: pprint

question = &quot;How to make a barplot in Makie.jl?&quot;
result = aihelp(question; search = true, rerank = true, return_all = true)
pprint(result) # nicer display with sources for each chunk/sentences (look for square brackets)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/generation.jl#L1-L70">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.docdata_to_source-Tuple{AbstractDict}" href="#AIHelpMe.docdata_to_source-Tuple{AbstractDict}"><code>AIHelpMe.docdata_to_source</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">docdata_to_source(data::AbstractDict)</code></pre><p>Creates a source path from a given DocStr record</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/preparation.jl#L1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.docextract" href="#AIHelpMe.docextract"><code>AIHelpMe.docextract</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">docextract(d::MultiDoc, sep::AbstractString = &quot;</code></pre><p>&quot;)</p><p>Extracts the documentation from a MultiDoc record (separates the individual docs within <code>DocStr</code> with <code>sep</code>)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/preparation.jl#L35-L41">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.docextract" href="#AIHelpMe.docextract"><code>AIHelpMe.docextract</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">docextract(modules::Vector{Module} = Base.Docs.modules)</code></pre><p>Extracts the documentation from a vector of <code>modules</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/preparation.jl#L71-L75">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.docextract" href="#AIHelpMe.docextract"><code>AIHelpMe.docextract</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">docextract(d::DocStr, sep::AbstractString = &quot;</code></pre><p>&quot;)</p><p>Extracts the documentation from a DocStr record. Separates the individual docs within <code>DocStr</code> with <code>sep</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/preparation.jl#L14-L21">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.docextract-Tuple{Module}" href="#AIHelpMe.docextract-Tuple{Module}"><code>AIHelpMe.docextract</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">docextract(mod::Module)</code></pre><p>Extracts the documentation from a given (loaded) module.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/preparation.jl#L50-L54">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.find_new_chunks-Tuple{AbstractVector{&lt;:AbstractString}, AbstractVector{&lt;:AbstractString}}" href="#AIHelpMe.find_new_chunks-Tuple{AbstractVector{&lt;:AbstractString}, AbstractVector{&lt;:AbstractString}}"><code>AIHelpMe.find_new_chunks</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">find_new_chunks(old_chunks::AbstractVector{&lt;:AbstractString},
    new_chunks::AbstractVector{&lt;:AbstractString})</code></pre><p>Identifies the new chunks in <code>new_chunks</code> that are not present in <code>old_chunks</code>.</p><p>Returns a mask of chunks that are new (not present in <code>old_chunks</code>).</p><p>Uses SHA256 hashes to dedupe the strings quickly and effectively.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/utils.jl#L3-L12">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.get_config_key-Tuple{PromptingTools.Experimental.RAGTools.AbstractRAGConfig, NamedTuple}" href="#AIHelpMe.get_config_key-Tuple{PromptingTools.Experimental.RAGTools.AbstractRAGConfig, NamedTuple}"><code>AIHelpMe.get_config_key</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Returns the configuration key for the given <code>cfg</code> and <code>kwargs</code> to use the relevant artifacts.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/pipeline_defaults.jl#L117">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.last_result-Tuple{}" href="#AIHelpMe.last_result-Tuple{}"><code>AIHelpMe.last_result</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">last_result()</code></pre><p>Returns the RAGResult from the last <code>aihelp</code> call.  It can be useful to see the sources/references used by the AI model to generate the response.</p><p>If you&#39;re using <code>aihelp()</code> make sure to set <code>return_all = true</code> to return the RAGResult.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/utils.jl#L42-L49">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.load_index!-Tuple{AbstractString}" href="#AIHelpMe.load_index!-Tuple{AbstractString}"><code>AIHelpMe.load_index!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">load_index!(file_path::AbstractString;
    verbose::Bool = true, kwargs...)</code></pre><p>Loads the serialized index in <code>file_path</code> into the global variable <code>MAIN_INDEX</code>.</p><p>Supports <code>.jls</code> (serialized Julia object) and <code>.hdf5</code> (HDF5.jl) files.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/loading.jl#L24-L31">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.load_index!-Tuple{PromptingTools.Experimental.RAGTools.AbstractChunkIndex}" href="#AIHelpMe.load_index!-Tuple{PromptingTools.Experimental.RAGTools.AbstractChunkIndex}"><code>AIHelpMe.load_index!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">load_index!(index::RT.AbstractChunkIndex;
    verbose::Bool = 1, kwargs...)</code></pre><p>Loads the provided <code>index</code> into the global variable <code>MAIN_INDEX</code>.</p><p>If you don&#39;t have an <code>index</code> yet, use <code>build_index</code> to build one from your currently loaded packages (see <code>?build_index</code>)</p><p><strong>Example</strong></p><pre><code class="language-julia hljs"># build an index from some modules, keep empty to embed all loaded modules (eg, `build_index()`) 
index = AIH.build_index([DataFramesMeta, DataFrames, CSV])
AIH.load_index!(index)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/loading.jl#L2-L16">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.load_index!-Tuple{Vector{Symbol}}" href="#AIHelpMe.load_index!-Tuple{Vector{Symbol}}"><code>AIHelpMe.load_index!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">load_index!(packs::Vector{Symbol}; verbose::Bool = true, kwargs...)
load_index!(pack::Symbol; verbose::Bool = true, kwargs...)</code></pre><p>Loads one or more <code>packs</code> into the main index from our pre-built artifacts.</p><p>Availability of packs might vary depending on your pipeline configuration (ie, whether we have the correct embeddings for it). See <code>AIHelpMe.ALLOWED_PACKS</code></p><p><strong>Example</strong></p><pre><code class="language-julia hljs">load_index!(:julia)</code></pre><p>Or multiple packs</p><pre><code class="language-julia hljs">load_index!([:julia, :makie,:tidier])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/loading.jl#L48-L66">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.load_index_hdf5-Tuple{AbstractString}" href="#AIHelpMe.load_index_hdf5-Tuple{AbstractString}"><code>AIHelpMe.load_index_hdf5</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Hacky function to load a HDF5 file into a ChunkIndex object. Only bare-bone ChunkIndex is supported right now.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/utils.jl#L52">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.update_index" href="#AIHelpMe.update_index"><code>AIHelpMe.update_index</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">update_index(index::RT.AbstractChunkIndex = MAIN_INDEX[],
    modules::Vector{Module} = Base.Docs.modules;
    verbose::Integer = 1,
    kwargs...)</code></pre><p>Updates the provided <code>index</code> with the documentation of the provided <code>modules</code>.</p><p>Deduplicates against the <code>index.sources</code> and embeds only the new document chunks (as measured by a hash).</p><p>Returns the updated <code>index</code> (new instance).</p><p>For available configurations and customizations, see the corresponding modules and functions of <code>PromptingTools.Experimental.RAGTools</code> (eg, <code>build_index</code>).</p><p><strong>Example</strong></p><p>If you loaded some new packages and want to add them to your MAIN_INDEX (or any <code>index</code> you use), run:</p><pre><code class="language-julia hljs"># To update the MAIN_INDEX as well
AIHelpMe.update_index() |&gt; AHM.load_index!

# To update an explicit index
index = AIHelpMe.update_index(index)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/loading.jl#L89-L112">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.update_pipeline!" href="#AIHelpMe.update_pipeline!"><code>AIHelpMe.update_pipeline!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">update_pipeline!(option::Symbol = :bronze; model_chat = MODEL_CHAT,
    model_embedding = MODEL_EMBEDDING, verbose::Bool = true, truncate_dimension::Union{
        Nothing, Integer} = nothing)</code></pre><p>Updates the default RAG pipeline to one of the pre-configuration options and sets the requested chat and embedding models.</p><p>This is a good way to update model types to change between OpenAI models and Ollama models.</p><p>See available pipeline options via <code>keys(RAG_CONFIGURATIONS)</code>.</p><p>Logic:</p><ul><li>Updates the global <code>MODEL_CHAT</code> and <code>MODEL_EMBEDDING</code> to the requested models.</li><li>Updates the global <code>RAG_CONFIG</code> and <code>RAG_KWARGS</code> to the requested <code>option</code>.</li><li>Updates the global <code>LOADED_CONFIG_KEY</code> to the configuration key for the given <code>option</code> and <code>kwargs</code> (used by the artifact system to download the correct knowledge packs).</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">update_pipeline!(:bronze; model_chat = &quot;gpt4t&quot;)</code></pre><p>You don&#39;t need to re-load your index if you just change the chat model.</p><p>You can switch the pipeline to Ollama models: Note: only 1 Ollama model is supported for embeddings now! You must select &quot;nomic-embed-text&quot; and if you do, set <code>truncate_dimension=0</code> (maximum dimension available)</p><pre><code class="language-julia hljs">update_pipeline!(:bronze; model_chat = &quot;mistral:7b-instruct-v0.2-q4_K_M&quot;,model_embedding=&quot;nomic-embed-text, truncate_dimension=0)

# You must download the corresponding knowledge packs via `load_index!` (because you changed the embedding model)
load_index!(:julia) # or whichever other packs you want!</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/pipeline_defaults.jl#L126-L156">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.Experimental.RAGTools.build_index" href="#PromptingTools.Experimental.RAGTools.build_index"><code>PromptingTools.Experimental.RAGTools.build_index</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">RT.build_index(modules::Vector{Module} = Base.Docs.modules; verbose::Int = 1,
    kwargs...)</code></pre><p>Build index from the documentation of the currently loaded modules. If <code>modules</code> is empty, it will use all currently loaded modules.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/preparation.jl#L112-L118">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.Experimental.RAGTools.build_index-Tuple{Module}" href="#PromptingTools.Experimental.RAGTools.build_index-Tuple{Module}"><code>PromptingTools.Experimental.RAGTools.build_index</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">RT.build_index(mod::Module; verbose::Int = 1, kwargs...)</code></pre><p>Build <code>index</code> from the documentation of a given module <code>mod</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/preparation.jl#L86-L90">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.@aihelp!_str-Tuple{Any, Vararg{Any}}" href="#AIHelpMe.@aihelp!_str-Tuple{Any, Vararg{Any}}"><code>AIHelpMe.@aihelp!_str</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">aihelp!&quot;user_question&quot;[model_alias] -&gt; AIMessage</code></pre><p>The <code>aihelp!&quot;&quot;</code> string macro is used to continue a previous conversation with the AI model. </p><p>It appends the new user prompt to the last conversation in the tracked history (in <code>AIHelpMe.CONV_HISTORY</code>) and generates a response based on the entire conversation context. If you want to see the previous conversation, you can access it via <code>AIHelpMe.CONV_HISTORY</code>, which keeps at most last <code>PromptingTools.MAX_HISTORY_LENGTH</code> conversations.</p><p>It does NOT provide new context from the documentation. To do that, start a new conversation with <code>aihelp&quot;&lt;question&gt;&quot;</code>.</p><p><strong>Arguments</strong></p><ul><li><code>user_question</code> (String): The follow up question to be added to the existing conversation.</li><li><code>model_alias</code> (optional, any): Specify the model alias of the AI model to be used (see <code>PT.MODEL_ALIASES</code>). If not provided, the default model is used.</li></ul><p><strong>Returns</strong></p><p><code>AIMessage</code> corresponding to the new user prompt, considering the entire conversation history.</p><p><strong>Example</strong></p><p>To continue a conversation:</p><pre><code class="language-julia hljs"># start conversation as normal
aihelp&quot;How to create a dictionary?&quot; 

# ... wait for reply and then react to it:

# continue the conversation (notice that you can change the model, eg, to more powerful one for better answer)
aihelp!&quot;Can you create it from named tuple?&quot;gpt4t
# AIMessage(&quot;Yes, you can create a dictionary from a named tuple ...&quot;)</code></pre><p><strong>Usage Notes</strong></p><ul><li>This macro should be used when you want to maintain the context of an ongoing conversation (ie, the last <code>ai&quot;&quot;</code> message).</li><li>It automatically accesses and updates the global conversation history.</li><li>If no conversation history is found, it raises an assertion error, suggesting to initiate a new conversation using <code>ai&quot;&quot;</code> instead.</li></ul><p><strong>Important</strong></p><p>Ensure that the conversation history is not too long to maintain relevancy and coherence in the AI&#39;s responses. The history length is managed by <code>MAX_HISTORY_LENGTH</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/macros.jl#L52-L89">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="AIHelpMe.@aihelp_str-Tuple{Any, Vararg{Any}}" href="#AIHelpMe.@aihelp_str-Tuple{Any, Vararg{Any}}"><code>AIHelpMe.@aihelp_str</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">aihelp&quot;user_question&quot;[model_alias] -&gt; AIMessage</code></pre><p>The <code>aihelp&quot;&quot;</code> string macro generates an AI response to a given user question by using <code>aihelp</code> under the hood. It will automatically try to provide the most relevant bits of the documentation (from the index) to the LLM to answer the question.</p><p>See also <code>aihelp!&quot;&quot;</code> if you want to reply to the provided message / continue the conversation.</p><p><strong>Arguments</strong></p><ul><li><code>user_question</code> (String): The question to be answered by the AI model.</li><li><code>model_alias</code> (optional, any): Provide model alias of the AI model (see <code>MODEL_ALIASES</code>).</li></ul><p><strong>Returns</strong></p><p><code>AIMessage</code> corresponding to the input prompt.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">result = aihelp&quot;Hello, how are you?&quot;
# AIMessage(&quot;Hello! I&#39;m an AI assistant, so I don&#39;t have feelings, but I&#39;m here to help you. How can I assist you today?&quot;)</code></pre><p>If you want to interpolate some variables or additional context, simply use string interpolation:</p><pre><code class="language-julia hljs">a=1
result = aihelp&quot;What is `$a+$a`?&quot;
# AIMessage(&quot;The sum of `1+1` is `2`.&quot;)</code></pre><p>If you want to use a different model, eg, GPT-3.5 Turbo, you can provide its alias as a flag:</p><pre><code class="language-julia hljs">result = aihelp&quot;What is `1.23 * 100 + 1`?&quot;gpt3t
# AIMessage(&quot;The answer is 124.&quot;)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/AIHelpMe.jl/blob/730f5ec9d350c621cc00599e3a354afff5266238/src/macros.jl#L1-L34">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../faq/">« F.A.Q</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.0 on <span class="colophon-date" title="Thursday 18 April 2024 09:15">Thursday 18 April 2024</span>. Using Julia version 1.10.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
